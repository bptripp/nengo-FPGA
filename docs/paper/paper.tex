\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{url}
\usepackage{marvosym}

\newcommand{\design}{Nengo\char`_FPGA}  %% Could be xFPGA to specify xilinx? since there might be other fpga backends

\begin{document}

\lstset{basicstyle=\footnotesize}

\title{Large-scale neural circuits on an FPGA}

% I don't care about order, just assumed you'd want to be 'senior author'
\author[1]{Murphy Berzish}
\author[1,2,3]{Chris Eliasmith}
\author[1,2]{Bryan Tripp}
\affil[1]{Centre for Theoretical Neuroscience, University of Waterloo}
\affil[2]{Dept. of Systems Design Engineering, University of Waterloo}
\affil[3]{Dept. of Philosophy, University of Waterloo}
\maketitle

\begin{abstract}
abstract goes here - bryan???
- ??? I think we want spiking neuron and population model simulation comparisons for the software simulations when comparing to hardware
\end{abstract}

\section{Introduction}

Large-scale neural models have recently become centrepieces of very large international research investments. The controversial European Human Brain Project (HBP) has a central goal of developing a human-scale neural simulation in the next 10 years, and has been granted \EURtm 1 billion to do so.  Similarly, the Obama Brain Initiative (OBI) in the US is investing well over \$1 billion over a similar timeframe in theoretical and experimental neuroscience. Both projects have identified massive increases in computational performance as a critical for achieving their goals.

One approach to solving this challenge is employing large supercomputers, such as the IBM BlueGene.  Both HBP and OBI have exploited this resource to simulation millions or billions of neurons, although not in real time.  However, such resources are available to only a select few researchers.

Another approach is to build specialized hardware -- often called ``neuromorphic'' hardware -- to massively increase the efficiency and speed of neural simulations.  There have been several exciting developments in this regards, both in industry and in academia.  IBM recently announced what will soon be the first commercially available neuromorphic chip \cite{Merolla2014}. As well, several academic projects, such as the SpiNNaker \cite{Khan2008} and Neurogrid \cite{Choudhary2012} projects have made impressive progress in recent years (see Section \ref{sub:neuromorphic} for further discussion).  However, these solutions are not available in large quantities, and hence remain inaccessible to a majority of researchers.

Here, we focus on developing an affordable and accessible solution to the problem of simulating large-scale neural circuits.  Our approach allows anyone with access to off-the-shelf FPGA hardware to simulate models up to about 10 million equivalent neurons with arbitrary connectivity in real time.

Importantly, this level of scaling is dependent on the notion of ``equivalent neurons.'' In Section {\ref{sub:NEF}} we discuss our theoretical approach that allows extremely good approximations of the activity of about a thousand spiking neurons by simulating them as a single population, at a resolution of about 1~ms.  Simulating large neural circuits at this level of abstraction allows for very computationally efficient solutions that preserve function. The main cost of this excellent computational scaling is that these methods do not allow online tuning of the connection weights between individual cells.  However, a large-class of adaptive and non-adaptive massively parallel circuits can be effectively simulated, providing a useful tool for exploring the class of brain-like algorithms.

Indeed, one of the main benefits of our approach is that it focusses both on function and biological plausibility, in contrast to work presented by HBP and OBI  which captures little function \cite{eliasmith2013a}.  This focus remains here, allowing the methods presented to be applied both to characterizing biological cognition and to exploring engineering applications of brain-like algorithms. To this end, we present examples that compute specific mathematical functions, as well as those that simulate early visual processing of time-varying stimuli.

We begin our discussion by describing related neuromorphic approaches in the next section.  We then explain our methods for constructing neural simulations, and demonstrate the equivalence between single cell and population-level simulations.  Next, we discuss the hardware design and show that it is able to efficiently simulate a variety of small test circuits.  We then show that the system scales efficiently to simulating very large models in real time. We conclude by discussing possible improvements to the current design.


\subsection{\label{sub:neuromorphic}Current Neuromorphic Hardware\protect\footnote{This discussion is based on that in \cite{eliasmith2015a}.}}

Perhaps best known neuromorphic hardware is that being developed by IBM.  The architecture itself is called TrueNorth. It includes a digital model of individual neurons, and a method for programming the architecture \cite{Esser2013}.  The purpose of this architecture is to exploit brain-like organization, to permit the simulation of a specific class of algorithms that do not efficiently run on classical computer architectures. IBM researchers argue that the ``low-precision, synthetic, simultaneous, pattern-based metaphor of TrueNorth is a fitting complement to the high-precision, analytical, sequential, logic-based metaphor of today's of von Neumann computers'' \cite[p.~1]{Esser2013}. 

TrueNorth has neurons organized into 256 neuron blocks in which each neuron can receive input from 256 axons. To assist with programming this hardware, IBM has introduced the notion of a ``corelet'', which is an abstraction that encapsulates local connectivity in small networks. These act like small programs that can be composed in order to build up more complex functions. To date the demonstrations of the approach have focused on simple, largely feed-forward, standard applications, although they have employed wide range of methods including RBMs, liquid state machines, HMMs, and very simple NEF networks. It should be noted that the proposed chip does not yet exist, and current demonstrations are on detailed simulations of the architecture. However, because it is a digital chip the simulations are highly accurate.

A direct competitor to IBM's approach is the Zeroth neuromorphic chip from Qualcomm. Like IBM, Qualcomm believes that constructing brain-inspired hardware will provide a new paradigm for exploiting the efficiencies of neural computation for the kinds of information processing that brains excel at, but which are extremely challenging for standard von Neumann approaches. The main difference between these 2 approaches is that Qualcomm has committed to allowing online learning to take place on the hardware. Consequently, they announced their processor by demonstrating its application in a reinforcement learning paradigm on a real-world robot. They have released videos of the robot maneuvering in an environment and learning to only visit one kind of stimulus (white boxes; \url{http://www.youtube.com/watch?v=8c1Noq2K96c}). It should again be noted that this is an FPGA simulation of a digital chip which does not yet exist. However the simulation, like IBM's, is highly accurate.  However, it has recently been suggested that Qualcomm is no longer fully supporting this research effort.

Both of these projects are spearheaded by industry.  In the academic sphere, the Spinnaker project at Manchester University has not focused on designing new kinds of chips, but instead focused on using low-power ARM processors at a massive scale to allow large-scale brain simulations \cite{Khan2008}. As a result, the focus has been on designing approaches to routing that allow for the high bandwidth communication that underwrites much of the brain's information processing. Simulations on the Spinnaker hardware typically employ spiking neurons, like IBM and Qualcomm, and occasionally allow for learning \cite{davies2013spike}, like Qualcomm's approach. However, even with low power conventional chips, the energy usage is projected to be higher on the Spinnaker platform per neuron. Nevertheless, Spinnaker boards have been used in a wider variety of larger-scale embodied, and non-embodied applications. These include simulating place cells, path integration, item classification, and simple sensory guided movements \cite{Stewart2013a}.

There are also a number of neuromorphic projects that use analog instead of digital implementations of neurons. Analog approaches tend to be several orders of magnitude more power efficient \cite{hasler2013}, although also more noisy, unreliable, and subject to process variation. These projects include work on the Neurogrid chip at Stanford University \cite{Choudhary2012}, and on a chip at ETH Z\"{u}rich \cite{Corradi2014}. The Neurogrid chip has demonstrated large numbers of simulated neurons, up to 1 million, while the ETH Z\"{u}rich chip allows for online learning. More recently, the Neurogrid chip has been used to control a nonlinear, 6 degree of freedom robotic arm, exhibiting perhaps the most sophisticated information processing from an analog chip to date \cite{Menon14:biorob}. 

In addition to the above neuromorphic projects, which are focused on cortical simulation, there have been several specialized neuromorphic chips that mimic the information processing of different perceptual systems. For example, the dynamic vision sensor (DVS) artificial retina developed at ETH Z\"{u}rich performs real-time vision processing that results in a stream of neuron-like spikes \cite{Lichtsteiner2008}. Similarly, an artificial cochlea called AEREAR2 has been developed that generate spikes in response to auditory signals \cite{Li2012}. The development of these and other neuronal sensors make it possible to build fully embodied spiking neuromorphic systems \cite{Galluppi2014}. 

More directly relevant to the present paper, there have be several attempts to build neuromorphic systems on FPGAs.  For instance, \cite{cassidy2011design} describe a design with a million ``neurons'', where each neuron is abstracted as an arithmetic logic unit.  In contrast to our design, all neurons are considered identical, there are no synaptic dynamics, and there is no modelling of neural noise. In \cite{li2012a}, synaptic dynamics are included, but the network consists of a total of 256 neurons.  More recently, in \cite{wang2013} a network of over 4 thousand neurons is implemented.  However, the approach we describe here is focussed on simulations of much larger numbers of effective neurons.

\section{Methods}

\subsection{\label{sub:NEF}The Neural Engineering Framework}

The Neural Engineering Framework (NEF) is method for constructing biologically realistic neural models \cite{Eliasmith1999s}.  Several overviews of the NEF are available \cite{Eliasmith2003f,Eliasmith2005p,stewart2012b,Eliasmith2012b}, but the description provided here is based on that in \cite{Stewart2014}.   
The NEF is a general-purpose approach to
implementing algorithms using components such
as spiking neurons \cite{Eliasmith2003m}. As a result, the NEF can be thought of
as a ``neural compiler'' where algorithms characterized by a high-level
mathematical description are converted into neural networks.
This compilation process works for arbitrary neuron types, and can
be constrained in biologically informed ways. Importantly, the high-level
description must be expressed in terms of vectors and functions on
those vectors (including differential equations). The resulting
neural networks approximate the desired functions, and the error of
this approximation can be made small by increasing the
number of neurons.

While the NEF can be used to build arbitrary abstract systems such
as controlled attractor networks \cite{Eliasmith2005p}, we have primarily
used it to show how particular capabilities found in real animals
might be implemented biologically. This has included path integration
in rodents \cite{Conklin2005b}, working memory \cite{Singh2006b}
and arm movements \cite{Dewolf} in monkeys, and decision-making in
rats \cite{Laubach2010,Liu2011} and humans \cite{Litt2008u}. We
have also taken into account biological constraints such as Dale's
Principle \cite{Parisien2008c} and incorporated biologically realistic
learning rules to construct these networks \cite{MacNeil2011a,bekolay2013}.

The remainder of this section serves as a summary of the three main principles
of the NEF. 

\subsection{Principle 1 - Representation}

In the NEF, groups of neurons are taken to represent vectors,
and connections between groups of neurons compute functions on those
vectors. The first NEF principle shows how the activity of a group
of neurons can be said to represent a vector, and how changes in the
activity of those neurons corresponds to changes in the represented
vector.

In the brain many neurons have a particular stimulus (or response) for
which they will fire most strongly. As an input stimulus (or response)
changes to become less similar to the preferred stimulus, the neuron
will fire less quickly.  This kind of behaviour was originally identified in the motor
system \cite{Georgopoulos1989q} and has since been seen in the head
direction system \cite{Taube2007}, visual system \cite{Rust2006},
and auditory system \cite{Fischer2009w}. The NEF identifies the preferred stimulus with a ``preferred direction vector'' associated with each neuron.  For a more detailed exploration of this idea, see \cite{Stewart2011a}.

In the NEF, we generalize this concept to all neural populations (those that are stimulus driven and those that are not).
In particular, we quantify it by stating that the total current going
into a neuron will be proportional to the dot product of the vector
to be represented, $\mathbf{x}$, and the preferred direction (or ``encoding'') vector
for the neuron, $\mathbf{e}_{i}$ (plus a constant bias term). The
response of a neuron \textbf{$i$} for any given input vector \textbf{$\mathbf{x}$}
is thus

\begin{equation}
\delta_{i}(\mathbf{x})=G_{i}[\alpha_{i}\mathbf{e}_{i}\mathbf{x}+J_{i}^{bias}]\label{eq:enc}
\end{equation}
where $\delta_{i}$ is the spiking output of the neuron, $G_{i}$
is the neuron model, $\alpha_{i}$ is a randomly chosen gain term,
$\mathbf{e}_{i}$ is the preferred direction vector, and $J_{i}^{bias}$
is a randomly chosen fixed background current. We use $\mathbf{e}$
for \textit{encoder} to indicate that (\ref{eq:enc}) captures a transformation
between spaces: \textbf{$\mathbf{x}$} is encoded in the activity
space of the neurons.  Importantly, the NEF applies
to a large variety of neuron models (including both spiking and non-spiking
models) since it makes no commitment to a specific function $G$ (whose
input is the total current flowing into the neuron). The leaky-integrate-and-fire
(LIF) model is a common choice, for reasons of computational efficiency, but a wide variety of
neural models work with the NEF. 

Given an encoding operation, it is natural to define a \textit{decoding} operation,
in order to characterize the information processing characteristics
of the system. To decode a continuous
estimate of the input from neural activity, the NEF focuses on the
postsynaptic filtered activity generated by the reception of a spike
at a synapse. This activity is taken to be a linear filter applied
to the spiking activity:
\[
a_{i}(\mathbf{x})=\sum_{j}h_{i}(t)*\delta_{i}(t-t_{j}(\mathbf{x}))
\]
where $h_{i}(t)$ is the synaptic response function (usually a decaying
exponential) with a time constant, $\tau_{PSC}$, determined by neurotransmitter
type at the synapse, '$*$' is the convolution operator, and $\delta_{i}(t-t_{j}(\mathbf{x}))$
is the spike train produced by neuron $i$ in response to input $\mathbf{x}$,
with spike times indexed by $j$. Having defined this continuous variable,
which is equal to the spike rate as $\tau_{PSC}\rightarrow\infty$,
we can specify a decoding operation for estimating the input $\mathbf{x}$:

\begin{equation}
\hat{\mathbf{x}}=\sum_{i}^{N}a_{i}\mathbf{(x)}\mathbf{d}_{i}\label{eq:dec}
\end{equation}
where $N$ is the number of neurons in the group, $\mathbf{d}_{i}$
are the linear decoders, and $\hat{\mathbf{x}}$ is the estimate of
the original $\mathbf{x}$ value that produced the neural activity
(\ref{eq:enc}). 

Any optimization method can be used to find these decoders. A simple example is least-squares optimization:
\begin{equation}
\underset{\mathbf{d}_{i}}{arg\, min}\int[\mathbf{x}-\sum_{i}^{N}a_{i}(\mathbf{x)}\mathbf{d}_{i}]^{2}d\mathbf{x}\label{eq:error}
\end{equation}
where $\mathbf{d}_{i}$ are the decoding vectors over which this error
is minimized and the integral is over all $\mathbf{x}$ values. As the number of neurons
$N$ increases, the mean squared error decreases as $1/N$. 

Note that employing linear decoding allows us to compute connection weights. This
is a key advantage of the NEF: rather than using a learning rule to
optimize over the entire space of all connection weights, we instead
solve the simpler problem of optimizing over the space of linear decoders,
and then use that result to solve for the connection weights. For example, if a connection between neural groups is meant to compute
the identity function $\mathbf{y}=\mathbf{x}$ (where $\mathbf{y}$
is the vector space represented by the second population B and $\mathbf{x}$
is the vector space represented by the first population A), the connections
between individual neurons are given by 
\begin{equation}
\omega_{ij}=\alpha_{j}\mathbf{d}_{i}\mathbf{e}_{j}\label{eq:weights}
\end{equation}
where $i$ indexes the neurons in group A and $j$ indexes the neurons
in B.

While the least-squares method for optimization is not
biologically plausible on its own, we have shown that biologically
realistic learning rules will converge to a similar solution \cite{MacNeil2011a}.
These realistic rules are, however, several orders of magnitude more
computationally expensive.

\subsection{Principle 2 - Transformation}

Principle 1 effectively assumes that we want to compute the identity function. Connections between groups of neurons can also compute functions other
than the identity function. That is, instead of \textbf{$\mathbf{y}=\mathbf{x}$}
we can compute \textbf{$\mathbf{y}=f(\mathbf{x})$}. We do this by finding
decoders \textbf{$\mathbf{d}_{i}^{f}$ }for the particular function\textbf{
$f(\mathbf{x})$} by substituting \textbf{$f(\mathbf{x})$ }for $\mathbf{x}$
in equation (\ref{eq:error}).

\begin{equation}
\underset{\mathbf{d}_{i}^{f}}{arg\, min}\int[f(\mathbf{x})-\sum_{i}a_{i}(\mathbf{x)}\mathbf{d}_{i}^{f}]^{2}d\mathbf{x}.\label{eq:error-fcns}
\end{equation}

The connection weights can then be computed using (\ref{eq:weights}).
For the special case of linear functions\textbf{ $\mathbf{y}=\mathbf{L}\mathbf{x}$},
rather than solving for a new decoder, we can simply put $\mathbf{L}$
directly into the weight equation itself, resulting in $\omega_{ij}=\alpha_{j}\mathbf{d}_{i}\mathbf{L}\mathbf{e}_{j}$.
Combining these two approaches, the neural connection weights needed
to approximate the function\textbf{ $\mathbf{y=L}f(\mathbf{x\textrm{)}}$}
are:
\begin{equation}
\omega_{ij}=\alpha_{j}\mathbf{d}_{i}^{f}\mathbf{L}\mathbf{e}_{j}\label{eq:weights-general}
\end{equation}


\subsection{\label{sub:Principle-3--}Principle 3 - Dynamics}

While the first two principles are sufficient to build neural approximations
of any desired feedforward function of the vector $\mathbf{x}$, the NEF also
provides a method for computing functions of the form \textbf{$\mathbf{\frac{\mathrm{d}x}{\mathrm{dt}}=}f(\mathbf{x},\mathbf{u})$},
where $\mathbf{u}$ is the input from some other population. The NEF exploits the fact that neurons do not simply accept input
as spikes. Rather, when a spike is transmitted from one neuron to
another, the actual current that flows into the second neuron is a
low-pass-filtered version of that spike. In particular, the post-synaptic
current is well-approximated by $h(t)=u(t)e^{-t/\tau}$, where $u(t)$
is the step function and $\tau$ is the time constant of the neurotransmitter
used. This time constant varies throughout the brain, e.g., from 2-5
ms (AMPA; \cite{jonas1993quantal}) up to $\sim$100ms (NMDA;
\cite{sah1990properties}). The effect of this filter is that instead
of a connection computing the function $\mathbf{y}(t)=f(\mathbf{x}(t))$
it will compute $\mathbf{y}(t)=f(\mathbf{x}(t))*h(t)$ (or, in the
Laplace domain, $\mathbf{Y}(s)=\mathbf{F}(s)H(s)$).

It turns out that this implicit low-pass filter can be used to generate
neural models that compute arbitrary dynamics. Given a neural population
representing $\mathbf{x}$, an input $\mathbf{u}(t)$, and a feedback
connection from $\mathbf{x}$ back to itself computing $g(\mathbf{x}(t))$,
we note that in the Laplace domain we get $\mathbf{X}(s)=(\mathbf{G}(s)+\mathbf{U}(s))H(s)$.
Since the Laplace transform of $h(t)=u(t)e^{-t/\tau}$ is $H(s)=1/(1+s\tau)$,
we can rearrange this to get $s\mathbf{X}(s)=(\mathbf{G}(s)-\mathbf{X}(s))/\tau+\mathbf{U}(s)/\tau$.
Converting back to the time domain, \textbf{$\mathbf{\frac{\mathrm{d}x}{\mathrm{dt}}=}\frac{g(\mathbf{x}(t))-\mathbf{x}(t)}{\tau}+\frac{\mathbf{u}(t)}{\tau}$}.
Thus, if we desire the dynamics \textbf{$\mathbf{\frac{\mathrm{d}x}{\mathrm{dt}}=}f(\mathbf{x}(t))+\mathbf{u}(t)$},
we introduce a feedback connection that uses the previous two NEF
principles to find connection weights that compute $g(\mathbf{x}(t))=\tau f(\mathbf{x})+\mathbf{x}$
and we scale the input $\mathbf{u}(t)$ by $\tau$. For arbitrary
dynamics of the form \textbf{$\mathbf{\frac{\mathrm{d}x}{\mathrm{dt}}=}f(\mathbf{x},\mathbf{u})$},
we do a change of variables $\mathbf{x}^{\prime}=\langle\mathbf{x},\mathbf{u}\rangle$. 

% @Chris: I don't get the last sentence above -- wasn't everything fine with x and u? 

This exploitation of the inherent first-order low-pass filter found
in synaptic connections allows for the implementation of a very wide
variety of systems, including oscillators, integrators, and arbitrary
attractor networks \cite{Eliasmith2005p}. 
This approach allows for the construction of neural models that correspond
to a very large family of functions, including those typically employed
by modern control theory and dynamic systems theory.

\subsection{Nengo}

The principles of the NEF have been incorporated into the Nengo neural simulator \cite{Bekolay2014}.  Nengo is a general purpose simulator that incorporates the three principles of the NEF.  It has been used to build what is currently the world's largest functional brain model \cite{Eliasmith2012b}, along with many other simulations. Full details and documentation can be found online at \url{http://github.com/nengo/nengo}.

One central feature of Nengo is that it permits the same model description to target a variety of ``backends.''  Current backends include CPUs, GPUs, the IBM BlueGene supercomputer, and several neuromorphic chips, including SpiNNaker \cite{Khan2008} and Neurogrid \cite{Choudhary2012}.  Because Nengo exploits the NEF methods, model descriptions can be very concise.  Model descriptions are written in python, although backends compile to a variety of languages, depending on the target hardware. For example, to create a recurrent model of a chaotic dynamical system (a Lorenz attractor) with 2000 spiking neurons and run it for 10 seconds, the following suffices:

\begin{verbatim}
import nengo

model = nengo.Network()
with model:
    state = nengo.Ensemble(2000, 3, radius=60)
	
	def feedback(x):
	    dx0 = -10 * x[0] + 10 * x[1]
	    dx1 = -x[0] * x[2] - x[1]
	    dx2 = x[0] * x[1] - 8.0/3 * (x[2] + 28) - 28
	
	    return [dx0 * 0.1 + x[0],
	            dx1 * 0.1 + x[1],
	            dx2 * 0.1 + x[2]]
	                
    nengo.Connection(state, state, function=feedback, synapse=0.1)
    state_probe = nengo.Probe(state, synapse=tau)
    
sim = nengo.Simulator(model)
sim.run(10)
\end{verbatim}

Nengo will use the NEF methods to automatically solve for the connection weights that will
best approximate the provided nonlinear, dynamic function.  To run this same network on a different backend, we only need change the second last line to indicate which simulator to use.

Nengo also provides an interactive interface for building models, and displaying the results of a simulation while it is running, allowing for real-time interaction
with a running model.

In this paper, we describe an extension to the Nengo simulator that allows models to compile to an FPGA, using a simulation method that efficiently approximates the computations performed by populations of spiking neurons (see "population mode", next section).

\subsubsection{Population mode}

Nengo can run network simulations in several different "modes", which provide different trade-offs between speed and accuracy. "Default mode" performs spiking simulations in the manner described above. In "rate mode", the simulator does not integrate the membrane dynamic equations, but instead calculates an analytical spike rate for each neuron based on its net input. Rate mode typically runs slightly faster than default mode, but it ignores high-frequency spike-related fluctuations in synaptic current. 
Another particularly useful mode is "direct mode". In direct mode, neurons are not simulated at all. Rather, the abstract dynamic equations, \textbf{$\mathbf{\frac{\mathrm{d}x}{\mathrm{dt}}=}\mathbf{f}(\mathbf{x}(t))+\mathbf{u}(t)$}, are simulated directly. These simulations are very fast, but they omit both spike-related fluctuations and also any static biases that arise from approximation of idealized functions with sums of spike rates. (Such biases are often substantial, particularly as spike rates saturate outside a population's normal operating range.) Despite this high level of abstraction, direct mode is very useful for rapidly prototyping and debugging high-level network function, and also for exploring differences between idealized network function and its approximation by neurons. 

We recently designed an additional new simulation mode \cite{Tripp2015}, which we call "population mode". In population mode, the simulator runs efficient surrogate models of population output. These models are slightly more computationally intensive than direct mode, but they are more realistic in that they include both static biases and spike-related fluctuations (similar to default mode). Specifically, they model the difference between the output of each population in default mode and direct mode, i.e. $\mathbf{e}(\mathbf{x},t)=\mathbf{f}(\mathbf{x})-\sum_{i}a_{i}(\mathbf{x)}\mathbf{d}_{i}^{\mathbf{f}}$. This difference is modelled as $\mathbf{e}(\mathbf{x},t)=\mathbf{s}_{\mathbf{x}}(t) + \mathbf{b}({\mathbf{x})}$, where $\mathbf{s}_{\mathbf{x}}(t)$ is the spike-related fluctuations (the difference between default and rate modes), and $\mathbf{b}(\mathbf{x})$ is the static bias (the difference between rate and direct modes). The bias model $\bar{\mathbf{b}}(\mathbf{x}) \approx \mathbf{b}(\mathbf{x})$ consists of an interpolation or regression between sampled values, and $\bar{\mathbf{s}}_{\mathbf{x}} \approx \mathbf{s}_{\mathbf{x}}$ consists of Gaussian white noise that is filtered to approximate the spectrum of the population's default-mode output fluctuations. This approach has been demonstrated in models of neural integrators, nonlinear oscillators, and dynamic neural fields \cite{Tripp2015}. 

The system introduced here is an implementation of population mode for field-programmable gate arrays. It is also the first Nengo backend to support population mode, since the approach was developed in stand-alone software. 

\subsubsection{Considerations related to hardware (multiplexing, clustering, using principal components)}

- Murphy???

% FIXME brief description of FPGA hardware and programming

\subsection{High-level system description}

\design{} is a custom digital hardware design that implements the population-mode NEF in real-time (1~ms timestep) on an FPGA.
A block diagram of the design is shown in Figure~\ref{fig:system}.
The encoder units perform the function of encoding (), % FIXME NEF equation
while the population units perform the decoding () % FIXME NEF equation
and write the decoded values to the decoded value buffers
to be used as inputs to other populations or as outputs from the network.
Each population of neurons is assigned to a population unit, which is able to simulate up to 1024 populations
having either one or two encoded inputs each. These inputs are calculated by the encoder units,
of which there are two for a one-dimensional population unit and four for a two-dimensional population unit;
each encoder unit can be associated with a different first-order filter to simulate post-synaptic filtering.
For example, one of the two encoders on a one-dimensional population unit can be programmed with
a small time constant to model fast synapses (e.g. AMPA and GABA$_A$), while the second can be programmed
with a large time constant to model slow synapses (e.g. NMDA and GABA$_B$).
Each population unit performs time-multiplexing and swaps in different sets of decoders
in order to run more populations on the same hardware. The principal components are fixed and must be shared
between all populations on an individual population unit.
Each population unit writes to a fixed set of decoded value buffers, but a shared interconnect
allows the encoder units to perform random accesses to these buffers.
This allows effective all-to-all communication between populations while reducing the number of 
connections that must be made between population units.
A number of decoded value buffers are reserved for external inputs to the network,
which can be sent from the controlling computer system over an Ethernet connection.
The output channels can also be programmed to send decoded values back to the computer over Ethernet.

\begin{figure}
\centering

\includegraphics[width=6in]{system-block-diagram.eps}

\caption{Block diagram of the \design{} hardware design.}

\label{fig:system}
\end{figure}

\subsection{Hardware design details}

\subsubsection{Encoder Unit}

It is too resource-intensive to create a connection from the output of each population unit to the inputs of all population units (including itself).
In order to allow communication of information across population units, the decoded values from each population are stored in a local buffer.
Then, every population unit has a number of encoder units that are responsible for reading decoded values from each buffer. 
Each encoder unit communicates with the decoded value buffers over a shared interconnect, described below.
A maximum of two encoder units are allowed to access a single decoded value buffer simultaneously
without causing a bus collision, since the memory primitives used to implement the buffers have two independent read ports.

Each encoder unit is attached to a circular buffer of size 8192
containing a list of instructions for calculating one encoded value. 
This size was chosen as a compromise between memory utilization and encoder flexibility;
it means that a single population can have a maximum fan-in of eight connections (including connections from the population to itself).
To execute an instruction, the encoder sends the decoded value address it wants to read from to the interconnect
and then reads the corresponding decoded value on its data input port three clock cycles later.
The value is then multiplied by a fixed-point weight, which is given as part of the instruction field, and added to an accumulator in the encoder.
The interconnect is responsible for routing address and value data between the encoders and the buffers.
A portion of the instruction field provides a delay (expressed as a number of clock cycles) to the encoder before executing this instruction.
This is necessary when many encoders are accessing the interconnect simultaneously in order to prevent too many of them from reading
from the same buffer at the same time (which would result in data corruption, because only two concurrent accesses are possible).
A certain bit in the instruction field acts as a flag to indicate that the encoded value is ready to be passed on to the population unit after this
instruction finishes executing. The encoder unit then waits for all other encoders to finish in order to synchronize
access to the shared interconnect, then resets the accumulator and begins encoding the next value.
To synchronize encoders across population units, a single encoding controller connects to all encoder units and is responsible for
signalling them to start encoding when it detects that they have all finished encoding the previous value.

\subsubsection{Population Unit}

Encoded values are passed from the encoder units to the population units. 
Population units are either one-dimensional or two-dimensional.
This means the groups of neurons they model have firing rates that are static functions of either a one- or two-dimensional represented variable.
Both types of population unit receive input from two encoder units in each input dimension;
for each dimension, the encoded values are passed through a first-order filter which performs post-synaptic filtering,
and are then summed. The value resulting from this operation is
truncated to the most significant 10 bits and is then used as input to a set of lookup tables,
implemented as a bank of synchronous RAM elements. SRAMs are used
because the contents of these tables are not known until simulation-time and therefore the lookups cannot be implemented as hardware logic functions.
Each lookup table contains the 12-bit fixed-point values of points sampled from 
principal components of the spike rates of neurons in a population, as a function of the variable that the population encodes.
In order to reduce the amount of memory used by each population, all populations on a population unit must share principal components.
For one-dimensional population units, there are seven such lookup tables, and each one contains
1024 values sampled at equally-spaced points on the open interval $(-2, 2)$. For two-dimensional population units,
there are fifteen lookup tables, each containing 1024 values sampled at equally-spaced points on a square of width 4
centered at $(0, 0)$. The resulting sample space is a 32x32 grid.
These numbers of principal components account for most of the variation in spike rates across 1D and 2D populations.
% FIXME find out exactly how much of this variation they account for over random populations with a variety of parameters, and mention this.
To increase the accuracy of this representation, each two-dimensional population unit performs bilinear interpolation
using the least significant five bits of each input variable to determine the distance between sample points. 
The extra resources used to perform this operation are modest
and significantly reduce the amount of memory used for two-dimensional populations while maintaining a good degree of accuracy of representation.

To simulate the noise resulting from a neural representation, a pseudorandom Gaussian noise generator is implemented in each population unit.
The output from the noise generator is passed through a pre-defined second-order filter to approximate the power spectrum of the noise
that would be present if individual neurons were being implemented. % FIXME for completeness, give the transfer function

The interpolated values from the principal component lookup tables and the filtered noise sample are multiplied by a vector of decoders,
and these results are summed to produce a decoded value. % FIXME refer to equations
One of the decoders corresponds to a gain term that can be used to control the amplitude of the noise.
Each population unit can store up to four independent sets of decoders per population being simulated,
which allows each population to produce a maximum of four decoded values as some function of its inputs
(and the resulting values of its principal components).

\subsubsection{Decoded Value Buffers and Interconnect}

Decoded values calculated from population units are stored in decoded value buffers, which are fairly large memory banks that can each
store 2048 decoded values. 
Because each population unit produces 4096 decoded values (1024 DVs from each of four decoder vectors),
this means that a population unit must be attached to the write ports of two separate decoded value buffers.
The buffers themselves expose a read-only interface, accessed by the encoders to read decoded values from the
previous timestep, and a write-only interface, accessed by the population units when new decoded values are calculated.
Internally, each interface is connected to a separate dual-port RAM; the connections are swapped between RAMs
at the end of each timestep in order to implement double-buffering, so that it is not possible for encoders to read a
partially-updated set of decoded values, where some are from the previous timestep and some are freshly written during the current timestep.
A diagram of this component is shown in Figure~\ref{fig:dvdoublebuffer}.
The reason for choosing a size of 2048 is because of this implementation detail; on the particular family of hardware
that was used to implement the prototype, the largest single-component 12-bit dual-port RAM available has space for 1024 words,
and two separate RAM components are necessary in order to implement the double buffer, hence a total size of 2048 words of memory.

\begin{figure}
\centering

\includegraphics[width=6.0in]{dv-double-buffer-diagram.eps}

\caption{Block diagram of the decoded value double-buffer component.}
\label{fig:dvdoublebuffer}
\end{figure}

The encoders must share access to the read-only interface of the decoded value buffers. To accomplish this,
the encoders are connected to the decoded value buffers over a shared interconnect. Access to the decoded value buffers
is managed by arbiters that inspect the addresses requested by encoders and redirect the read operations to the
corresponding buffers. A maximum of two encoders may be accessing a single buffer at any one time.
Therefore, it is up to the compiler to generate a sequence of read instructions for the encoders that ensures that this
constraint is respected. The delay field in the encoder instruction word can be used for this purpose to make an encoder
wait until another is finished with its access before attempting to read from the same buffer.

\subsubsection{Input, Output, and Control}

A number of decoded value buffers, which can be customized at the time the hardware is synthesized
(but always at least one)
are set aside for use as inputs to the simulation. These are indistinguishable from other decoded value buffers
from the perspective of the encoders and interconnect, but instead of being written to by population units,
they are connected to one or more input channels which are responsible for receiving data from an external source
and writing it to the buffers.

To provide output to an external source, such as a simulation GUI running on a computer, one or more output channels
are made accessible on the hardware. The exact number of output channels, as well as their features, will depend on the hardware used to implement the design.
The function of the output channel is to read from the decoded value buffers and output the desired decoded values to be transmitted
to an external device. Output channels do not have access to the interconnect until all encoders have finished all
encoding operations for this timestep. At that point, the encoders are detached from the interconnect by a separate controller and the output
channels are attached in their place. This allows the output channels to share interconnect logic with the encoders;
it also increases efficiency both by reducing contention on the shared interconnect (as the encoders and output channels
do not access it at the same time) and by allowing output to happen at the same time as decoding
(the double-buffering of decoded values means that output channels always see a consistent set of values,
so these operations can be performed in parallel).

Both the input and output channels are transport-agnostic and can be attached to application-specific custom hardware that allows for
I/O to be performed over the desired interface, such as Ethernet. The implemented design performs I/O over Gigabit Ethernet using a custom Ethernet frame format for efficiency.
Input and output channels could also be implemented for sensors and actuators to allow for autonomous operation of a Nengo network in hardware once it has been sent to the board
(Figure~\ref{fig:closedloop}).

\begin{figure}
\centering

\includegraphics[width=5.0in]{robot-closed-loop.eps}

\caption{Block diagram of a high-level closed-loop autonomous system using \design{}.}
\label{fig:closedloop}
\end{figure}

The top-level module exposes a programming interface that allows for any of the runtime configurable components
(decoded value buffers, encoders, population unit filters, principal component lookup tables,
population unit noise generators, decoder vectors, and I/O channels) to be initialized and programmed
over an external interface such as Ethernet. This allows a single implementation of the design
to be used to simulate a large number of different neural networks without requiring modifications to the physical hardware.
The programming interface also allows an external controller to reset the hardware and to start, pause, or single-step a simulation
without requiring physical access to the hardware.

\subsection{Constraints on models}

There is a limitation on the complexity of the encoding operation due to the length of the instruction buffer that is used.
Because each encoder must produce 1024 encoded values per timestep, using an instruction memory of size 8192 for each encoder means that a maximum of eight decoded values
can be used as input to each encoder per population.
If a higher fan-in is required, the hardware design could be modified to allocate more memory to the instruction buffers,
which in turn would reduce the amount of memory available for other portions of the design.
It is theoretically possible to simulate populations that require more than eight decoded values to be read by a single encoder
without increasing the size of the instruction buffers,
but the extra instructions used for this mean that other populations sharing that encoder will have to use fewer.
The compiler can detect this scenario and reorganize populations appropriately so as to avoid overfilling the instruction buffers.

As only one-dimensional and two-dimensional population units have been implemented, networks that require populations to compute functions
of three or more independent variables cannot be simulated with this design.
However, the majority of existing models in Nengo do not use populations with more than two input dimensions.
A controlled oscillator is an example of a kind of NEF network that cannot be simulated in our hardware implementation,
because it requires the approximation of a three-dimensional nonlinear function. Our implementation can simulate higher-dimensional representations
by simulating dimensions individually or in pairs, as long as each approximated function is either linear or is nonlinear in only one or two dimensions.

The choice of using a maximum of four sets of decoder vectors per population is arbitrary; it seems to be a good balance between
population connectivity and memory usage. Populations that have more than four outgoing connections must be treated specially.
Assuming none of the outgoing connections can be combined together (for example, if the function they decode only differs by a constant),
in order to implement such a population on the simulator, it is necessary to duplicate it and simulate it
$n/4$ times, once for each group of up to four decoder vectors.
The consequence of this is that a population with more than
four outgoing connections will be represented as two or more populations in simulation, thereby reducing the actual number of
distinct populations that can be simulated.

\subsection{Implementation details}

A hardware implementation of the \design{} design was produced on a Xilinx VC707 development board, which includes a modern field-programmable gate array (FPGA)
device (Xilinx XC7VX485T-2FFG1761C). This device was chosen because of its ready availability on a development platform and its large logic capacity and available resources.
In particular, it provides 37080~Kb of on-chip block RAM and 2800 customizable DSP slices, both of which the Nengo-RT design requires in abundance.
Table~\ref{tbl:utilization} outlines the resource utilization of the implemented design.

\begin{table}
\begin{tabular}{|r|c|c|l|}
\hline
Resource & Used & Total & \% Used \\
\hline
\hline
Registers & 82~149 & 607~200 & 13\% \\
Lookup Tables & 101~859 & 303~600 & 33\% \\
Logic Slices & 43~596 & 75~900 & 57\% \\
Block RAM (18~Kb) & 914 & 2060 & 44\% \\
DSP & 1722 & 2800 & 61\% \\
\hline
\end{tabular}
\caption[\design{} resource utilization on VC707 development board.]
{Resource utilization of the \design{} design with 7 one-dimensional and 7 two-dimensional population units, and one decoded value buffer reserved for external inputs.
Resource totals are for the Xilinx XC7VX485T device.}
\label{tbl:utilization}
\end{table}

The implemented hardware operates at a clock speed of 125~MHz, using the same external clock source as the Gigabit Ethernet transceiver.
This is convenient as it means that the entire design, including both the simulator hardware and the I/O interfaces, operates from the same clock source.
Because of this, there is no latency when receiving input or transmitting output to and from the simulation;
if two different clock speeds were used, extra buffers would have to be implemented in order to ``cross'' the two clock domains,
and the logic operating in the faster clock domain would occasionally have to wait for the slower-clocked logic to consume input from the buffer.
This type of stall would prevent part of the simulator from operating in real-time; by using the same clock for all logic, however, this problem is averted and
both input and output are wait-free.

Power analysis showed that the implemented design, with 7 one-dimensional and 7 two-dimensional population units,
is estimated to use a maximum of 5.675~W of power while a simulation is running, assuming all population units are fully utilized.
For an individual population unit, a one-dimensional unit consumes an average of 0.130~W of power during simulation,
and a two-dimensional unit consumes an average of 0.425~W of power.
With the installed heatsink and fan on the VC707 board, the FPGA is expected to operate at an on-die temperature of $31.5\,^{\circ}{\rm C}$.

The VC707 development board provides a Gigabit Ethernet transceiver that can be used for fast off-board communication to a PC.
A simple Ethernet stack was implemented as part of the Nengo-RT design to expose a programming interface to the Nengo software,
as well as to provide input and output of decoded values during simulation.

% FIXME maximum channel capacity in terms of decoded values

\subsection{Nengo backend}

% FIXME quick description of Nengo
Nengo's ensembles of neurons become populations that are simulated in the hardware on population units.
Connections between populations are handled through encoders and decoders.
Nodes and probes, which collect data or evaluate arbitrary functions in software, are
simulated on the host computer and are transferred to and from the board over hardware 
I/O channels after every timestep. 
By default, the hardware operates in real-time; the software receives new output data from the board
every millisecond and is responsible for processing this data and sending new inputs back to the hardware as quickly as possible.
The software does not have to send inputs for every timestep; if no new data is sent, the old values will be preserved.
This means that more work can be done in software while still operating the hardware in real-time by, for example,
only computing new input values every fifth timestep.
If strict synchronization is necessary, or if real-time operation is not possible,
the hardware can be run in a single-step mode, which forces it to pause after completing each timestep in order
to allow the software time to complete its tasks, which may include updating plots, logging received data to a file,
computing node functions, and calculating and sending new input values to the hardware.
This mode of operation, while not real-time, makes it possible to run hardware-assisted simulations
on a slower PC or when the software component is too complex or slow to be performed in sync with the hardware
(for example, logging a large number of decoded values to a hard drive).

A backend to Nengo performs the task of compiling a Nengo model to a loadfile that can be
simulated on the hardware. The compiler calculates principal components for each population
of neurons, and then performs a clustering operation in order to associate many
populations with each set of principal components while minimizing the differences
between the approximate principal components and the actual values. 

Populations must share principal components because storing a separate set of principal components for each population would require
an unreasonably large amount of memory. As an example, a one-dimensional population currently uses seven principal components,
each of which is a 1024-word, 12-bit block memory, for a total of 86~016~bits of memory per population.
The FPGA on the VC707 development board has a maximum of approximately 37~080~000~bits of block memory;
if we allowed each population to use its own principal components, we could not simulate more than 431 populations this way
(and this number is halved for two-dimensional populations, which use 15 principal components).
Therefore, in order to simulate large numbers of populations, it is necessary for large groups of populations to share principal components,
even though this is not as accurate as providing a ``real'' set of principal components for each separate population.

The compiler calculates decoders and encoders for each population with respect
to the shared principal components, and computes an optimized encoder schedule % FIXME details needed here
that coordinates reads made by each encoder so that all operations can be performed
in as few clock cycles as possible while avoiding a read collision on any decoded value block.
Once the compiler has finished writing out the loadfile, the Nengo simulator
transfers the configuration data to the hardware and controls input and output during the simulation.

% clustering algorithm, quantization error for large populations -- this needs its own section

\section{Results}
- ??? Schematics could come from the Nengo visualizer, for consistency and ease.
% integrator (1d)
% oscillator (2d)
% feed-forward nonlinear functions
% 2D multiplication

% scope of situations for which it works well
% full neurons vs. CPU populations vs. hardware populations
% high-frequency breakdown (square wave, sinusoids)
% qualitative comparison: show the figure, talk about the figure
% possible quantitative approach (RMSE)

% hardware-specific results: how many populations, 
% circumstances under which an overflow could occur
% (probabilistic analysis), power analysis,
% resource utilization

% FIXME may need a simpler example first -- just an input driving an identity population from 0 to 0.5 in steps of 0.1. This is good for contrast.

To verify the correct operation of the hardware as well as the software backend to Nengo, a simple network consisting of a single neural integrator was compiled and simulated on the hardware.
Figure~\ref{lst:integrator1d} shows the code listing and the resulting network that it describes.
\begin{figure}
\centering

\begin{subfigure}[b]{\textwidth}
\centering
\lstset{language=Python}
\begin{lstlisting}[frame=single]
import nengo
import nengo.helpers
model = nengo.Model(label='Integrator')
input = nengo.Node(nengo.helpers.piecewise({0:0.5}), label='Input')
tau = 0.1
A = nengo.Ensemble(nengo.LIF(100, tau_rc=0.02, tau_ref=0.002,
                   dimensions=1, label='Integrator'))
nengo.Connection(A, A, transform=[[1]], filter=tau)
nengo.Connection(input, A, transform=[[tau]], filter=tau)
p1 = nengo.Probe(input, 'output')
p2 = nengo.Probe(A, 'decoded_output', filter=0.01)
\end{lstlisting}
\caption{Source code}
\label{lst:integrator1d:code}
\end{subfigure}

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=3.0in]{integrator-1d-schematic.eps}
\caption{Schematic}
\label{lst:integrator1d:schematic}
\end{subfigure}

\caption[A 1D neural integrator in Nengo.]
{Source code (\ref{lst:integrator1d:code}) and schematic (\ref{lst:integrator1d:schematic}) of a 1D neural integrator in Nengo.}
\label{lst:integrator1d}
\end{figure}

% FIXME explanation of the code?
The network was compiled with the \design{} backend to produce a programming file that could be used to configure the simulator hardware.
Simulation output from the FPGA was captured with an Ethernet traffic sniffer and plotted in Figure~\ref{fig:integrator1d}.

\begin{figure}[h!]
\centering

\begin{subfigure}[a]{0.4\textwidth}
\includegraphics[width=4in]{integrator-1d.eps}
\caption{Hardware simulation}
\label{fig:integrator1d:hw}
\end{subfigure}

\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=4in]{integrator-1d-sw.eps}
\caption{Software simulation}
\label{fig:integrator1d:sw}
\end{subfigure}

% FIXME figure: larger axis and label font, make this consistent across all figures

\caption[Simulation of a 1D neural integrator.]
{Hardware (\ref{fig:integrator1d:hw}) and software (\ref{fig:integrator1d:sw}) output from simulation of a one-dimensional population representing a neural integrator.}

\label{fig:integrator1d}
\end{figure}

Given a constant input value of 0.5, the output from the integrator approaches this value
over time and reaches it after 1.0 seconds, then continues to accumulate the input until
another second has elapsed. The population saturates and remains at 1.0 after this time
because it is not able to represent values with a magnitude greater than 1.0. However,
the integrator's behaviour for the first two seconds of simulation is correct and confirms
the proper operation of the one-dimensional population hardware.

The two-dimensional population unit was tested with a simple single-population van der Pol oscillator.
Figure~\ref{lst:oscillator2d} shows the code listing and the network generated in Nengo;
Figure~\ref{fig:oscillator2d} shows output from the \design{} hardware simulation.

\begin{figure}
\centering

\begin{subfigure}[a]{\textwidth}
\centering
\lstset{language=Python}
\begin{lstlisting}[frame=single]
import nengo
import nengo.helpers
model = nengo.Model('Oscillator')
neurons = nengo.Ensemble(nengo.LIF(200), dimensions=2, 
  label='van der Pol Oscillator')
input = nengo.Node(output=nengo.helpers.piecewise(
  {0:[1,0], 0.1:[0,0], label='Initial condition')
tau = 0.1
freq = 5.0
input2output = nengo.Connection(input, neurons)
recurrent = nengo.Connection(neurons, neurons, 
  transform=[[1, -freq*tau],[freq*tau,1]], filter=tau)
input_probe = nengo.Probe(input, 'output')
neuron_probe = nengo.Probe(neurons, 'decoded_output', filter=0.005)
\end{lstlisting}
\caption{Source Code}
\label{lst:oscillator2d:code}
\end{subfigure}

\begin{subfigure}[b]{0.3\textwidth}
\centering
% FIXME \includegraphics[width=3.0in]{oscillator-2d-schematic.eps}
\caption{Schematic}
\label{lst:oscillator2d:schematic}
\end{subfigure}

\caption[A 2D neural oscillator in Nengo.]
{Source code (\ref{lst:oscillator2d:code}) and schematic (\ref{lst:oscillator2d:schematic})
of a 2D neural oscillator in Nengo.}
\label{lst:oscillator2d}
\end{figure}

\begin{figure}[h!]
\centering

\begin{subfigure}[a]{0.4\textwidth}
\centering
\includegraphics[width=4in]{oscillator-2d.eps}
\caption{Hardware simulation}
\label{fig:oscillator2d:hw}
\end{subfigure}

\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=4in]{oscillator-2d-sw.eps}
\caption{Software simulation}
\label{fig:oscillator2d:sw}
\end{subfigure}

\caption[Simulation of a 2D neural oscillator in hardware and software.]
{Hardware (\ref{fig:oscillator2d:hw}) and software (\ref{fig:oscillator2d:sw}) output from the simulation of a two-dimensional population representing a neural oscillator.}
\label{fig:oscillator2d}
\end{figure}

The oscillator requires a brief non-zero ``start-up'' input in order to begin oscillating.
After this input disappears (0.1~s), both dimensions of the decoded output can be seen to
oscillate in a sinusoidal fashion. This oscillation, once started, will proceed indefinitely.
The oscillation as observed in the figure confirms the correct operation of the two-dimensional
population hardware.

As a test of a combined network with both one-dimensional and two-dimensional populations,
a neural multiplier was simulated on the hardware. Figure~\ref{lst:multiplier} shows
the code listing and the resulting network that it describes.

\begin{figure}
\centering

\begin{subfigure}[b]{\textwidth}
\centering
\lstset{language=Python}
\begin{lstlisting}[frame=single]
import nengo
import nengo.helpers
model = nengo.Model('Multiplier')
A = nengo.Ensemble(nengo.LIF(100), dimensions=1,
  radius=1.4, label='A')
B = nengo.Ensemble(nengo.LIF(100), dimensions=1,
  radius=1.4, label='B')
combined = nengo.Ensemble(nengo.LIF(224), dimensions=2,
  radius=2, label='combined')
prod = nengo.Ensemble(nengo.LIF(100), dimensions=1,
  radius=2, label='prod')

inputA = nengo.Node(nengo.helpers.piecewise
  ({0:0, 2.5:0.5, 4:-0.5}))
inputB = nengo.Node(nengo.helpers.piecewise
  ({0:1.0, 1.5:0.8, 3:0.0, 4.5:0.8}))

nengo.Connection(inputA, A)
nengo.Connection(inputB, B)

nengo.Connection(A, combined, transform=[[1],[0]])
nengo.Connection(B, combined, transform=[[0],[1]])

def product(x):
  return x[0] * x[1]

nengo.Connection(combined, prod, function=product)

A_probe = nengo.Probe(A, 'decoded_output', filter=0.01)
B_probe = nengo.Probe(B, 'decoded_output', filter=0.01)
prod_probe = nengo.Probe(prod, 'decoded_output', filter=0.01)
\end{lstlisting}
\caption{Source code}
\label{lst:multiplier:code}
\end{subfigure}

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=3.0in]{multiplier-schematic.eps}
\caption{Schematic}
\label{lst:multiplier:schematic}
\end{subfigure}

\caption[A multiplier in Nengo.]
{Source code(\ref{lst:multiplier:code}) and schematic (\ref{lst:multiplier:schematic})
of a multiplier in Nengo.}
\label{lst:multiplier}
\end{figure}

Simulation of this network in hardware produced results comparable to those obtained in software
(Figure~\ref{fig:multiplier}).

\begin{figure}
\centering

% FIXME change the bounds on the axes to make it easier to see the similarities

\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=4in]{multiplier-sw.eps}
\caption{Software}
\label{fig:multiplier:sw}
\end{subfigure}

\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=4in]{multiplier.eps}
\caption{Hardware}
\label{fig:multiplier:hw}
\end{subfigure}

\caption[Multiplier simulation comparison.]
{Comparison of software (\ref{fig:multiplier:sw}) and hardware (\ref{fig:multiplier:hw})
simulation of a neural multiplier network.}
\label{fig:multiplier}
\end{figure}

\section{Large-scale simulation}

As an example of a large, real-time simulation, we adapted an existing model of visual motion sensitivity (ref Aziz). The original version of this model illustated a mechanism by which motion selectivity might arise from recurrent connections within V1. This mechanism is interesting because recurrent connections are anatomically prominent, but absent from classical models of motion selectivity (ref Hubel).  
The recurrent connections are optimized, using the NEF, to approximate two-dimensional damped linear oscillators. Each oscillator receives subcortical burst input due to visual features at multiple spatial phases within the receptive field. Inputs from different parts of the receptive field drive the oscillator state in different directions. 
As an example, consider a population in which input from the left half of the receptive field drives the oscillator state to the right, and input from the right half drives the state to the left. Suppose the oscillator state is initially zero, and a visual feature travels across the receptive field from left to right. When the input is on the left, it will drive the oscillator state from zero to the right. This will begin a damped oscillation, and a short time later the state will be travelling to the left. If input from the right half of the receptive field arrives at this time, it will drive the oscillator state further to the left, amplifying the oscillation. 
Because the oscillator is damped, neurons that represent later states in the cycle are only active following this kind of constructive interference. These late-phase neurons provide output to MT populations. MT populations therefore respond to motion at speeds that maximize constructive interference in the corresponding V1 oscillators.  

Our implementation of the model included 4500 oscillator populations of 200 motion-selective neurons each. These neurons had small, Gabor-shaped spatial receptive fields (roughly 40-pixel diameter). The populations varied in the positions of their receptive fields, and their direction and speed preferences. Six additional populations modelled a small part of area MT. Each of the MT populations received converging input from 100 V1 populations that spanned a receptive fields 400 pixels in diameter. 

The model accepted 400x400 pixel, 100 frame/s video as input. As an abstraction of subcortical processing, each video frame was convolved with a difference-of-Gaussians filter. The V1 and MT populations ran at 1000 steps/s. Input to the neural model consisted of a 400x400-pixel input, $\mathbf{u}$, which was calculated from the most recent video frame. Specifically, pixels of $\mathbf{u}$ in which the filtered image both exceeded a threshold and exceeded its value in the previous frame were set to a high value for the next 6ms. This modelled bursting in magnocellular lateral geniculate nucleus (ref Aziz). 

Each V1 population received weighted input from $\mathbf{u}$ in a spatially restricted receptive field. To set the weights, the difference-of-Gaussian functions used in the subcortical model were combined in a weighted sum, and the weights were optimized so that the weighted sum approximated Gabor functions. Groups of three Gabor functions with the same orientation and spatial frequency, but different phases, defined the inputs to groups of six V1 populations with the same spatial receptive field but different direction and speed preferences (see Figure) [TODO: picture of left, centre, right Gabor functions in 400x400 image; picture of dots]. The abstract population dynamics of the leftward-sensitive populations was 

\[
\dot{\mathbf{x}} = 
\left[
\begin{array}{cc}
-\zeta & \omega \\ 
-\omega & -\zeta \\ 
\end{array}
\right]
\mathbf{x} + 
\left[
\begin{array}{c}
\mathbf{w}_l^{T} - \mathbf{w}_r^{T} \\ 
-\mathbf{w}_c^{T} \\ 
\end{array}
\right]
\mathbf{u}
\]

where $\omega$ is the oscillator frequency, $\zeta$ is the damping ratio, and $\mathbf{w}_l$, $\mathbf{w}_c$, and $\mathbf{w}_r$ are vectors of the weights for the left, centre, and right Gabors, respectively. The first state variable was therefore driven to increase in response to input on the left and decrease in response to input on the right of the receptive field. The second state variable was driven to decrease in response to input in the centre of the receptive field. A stimulus passing across the receptive field from left to right at the right speed would therefore interfere constructively with the (clockwise) intrinsic oscillation of the population state. Input to the leftward-sensitive populations was the same except that the sign of the left and right signs were exchanged. To limit the size of the model, we only included populations sensitive to leftward and rightward motion (Our system is not able to simulate all of primate V1 on a single FPGA.) Full source code is available from the authors' web site (ref). 

Figure XX shows simulations with coherent random dot stimuli. On the left are decoded outputs of representative V1 and MT populations from a spiking software simulation (default mode). On the right are the corresponding outputs from a population-mode simulation on the FPGA. The outputs are similar in each case. However, while the FPGA simulation ran in real time, the software software simulation ran at 1/??? real-time and consumed much more power. 

\section{Discussion}

\subsection{How well it worked}

\subsection{Limitations}

Our current implementation does not support populations that represent variables of three or more dimensions.
Support for higher-dimensional populations could be added in the future.
However, as the number of dimensions increases, the
amount of memory that must be used to store principal components and
decoders increases as well; therefore, beyond a certain number of
dimensions it would become impractical to implement a hardware
population unit.  

Nengo supports a more advanced connection called a learning connection,
which modifies the decoders of a population according to a particular ``learning rule''
as a function of other represented values. The hardware design does not support this special connection type.
It was decided to implement the most common cases first in order to demonstrate the feasibility of simulating
neural networks in population mode on the hardware, and since many networks do not use learning connections,
support for them was omitted from this version.

Most connections in Nengo have both positive and negative synaptic weights. This
structure is meant as a simplified model of a common excitatory/inhibitory circuit
(Parisien et al.) % FIXME citation
Nengo also has a special kind of connection called an inhibitory connection that
reduces activity in all neurons of the target population. We did not model this kind of connection explicitly.
However, such a connection onto a 1D population could be modelled by treating the population as 2D,
setting the second element of each neuron's encoder to -1, and connecting inhibitory inputs to this dimension.

% high-frequency stuff (this will depend on other results)

\subsection{Future work \& extensions}

The flexibility of input and output channels lends to their use in connecting multiple devices together for use as part of a larger simulation engine.
This would allow networks to be simulated that consume more resources than are available on a single device, which may in turn allow
for ``grids'' of inexpensive hardware devices to be used to simulate a very large model.

The current control and I/O interface communicates over Ethernet, but since bare frames are being used with no higher-level protocols on top of them,
it is somewhat cumbersome to set up a computer or other device to send and receive data to the hardware.
This approach is suitable for testing and prototyping, but it makes certain assumptions about the setup of the network and the host computer that
may not be reasonable for general use, such as requiring raw socket privileges on the host operating system (which typically require administrator access).
A more user-friendly approach would be to implement an Ethernet stack that supports a protocol such as UDP, which can be readily used by many different
kinds of host software in order to interact with a simulation.

At present, the interconnect between the encoders and the decoded value
buffers is the most complex part of the design in terms of the density of its logic
in hardware. If there are $N$ encoders and $M$ decoded value buffers, a total of
$NM$ connections must be made between these components in order for every
encoder to be able to read from every decoded value buffer.
Note that this is still a massive improvement over a neuron-to-neuron interconnect,
which would require over 10000 times as many connections to provide all-to-all connectivity.
For large numbers of encoders and decoded value buffers, the complexity of the interconnect at
that design size makes it impossible for the FPGA design tools to find a way to
implement that part of the design on the device. This is currently the limiting
factor in terms of the number of population units that can be implemented on
the development board (as opposed to, for example, a lack of memory blocks for
decoded value buffers). A future version of the \design{} design may address
this issue and implement an interconnect that scales well to larger numbers of
encoders and decoded value buffers in order to allow more populations to be
simulated. % FIXME how could this be done?

\subsection{Conclusion}
We have presented a new neuromorphic system based on commodity FPGA hardware. We emphasize that FPGA expertise is not needed to use this system. Models can be developed for the system using the Nengo simulator, and implemented in hardware with a single additional Python command. 
Compared to existing FPGA approaches to neural simulation, our use of surrogate population models allows a substantial increase in model scale, with associated constraints (e.g. on fan-in, fan-out, and population dimension), and loss of fidelity. 
However, many existing models are already consistent with these constraints, and further loss of fidelity relative to real neural systems may not be much greater than with point-neuron models, which are already highly simplified. 
The increase in scale raises the possibility of simulating more extensive neural systems that are capable of richer interactions with the physical world. 
Because population inputs are transport-agnostic, this system could also potentially be used for very large, power-efficient simulations, by connecting multiple FGPAs through Ethernet or the FPGAs' general-purpose input/output pins. 
In summary, this work provides a practical and accessible new way to implement neuromorphic systems. 

\bibliographystyle{acm}
\bibliography{references}

\end{document}
